name: Test Suite

on:
  push:
    branches: [main]
  pull_request:
    branches:
      - main
      - 'release/**'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  # Fast unit tests - run first for quick feedback
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run unit tests
        run: |
          pytest tests/unit -v --tb=short -n auto \
            --junitxml=test-results/unit-results.xml \
            --cov=src --cov-report=xml --cov-report=term-missing

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: test-results/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: coverage.xml

  # Integration tests with real database
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests  # Only run if unit tests pass

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test_db
          ENVIRONMENT: test
          DATABRICKS_HOST: https://test.cloud.databricks.com
          DATABRICKS_TOKEN: test-token
        run: |
          pytest tests/integration -v --tb=short -n auto \
            --junitxml=test-results/integration-results.xml \
            -m "not live"

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: test-results/

  # E2E tests with Playwright
  e2e-tests:
    name: E2E Tests (Playwright)
    runs-on: ubuntu-latest
    needs: unit-tests  # Only run if unit tests pass

    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Install Playwright browsers
        working-directory: frontend
        run: npx playwright install --with-deps chromium

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install backend dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Start backend server
        run: |
          # Start backend with test database in background
          DATABASE_URL="sqlite:///./test.db" \
          ENVIRONMENT="test" \
          DATABRICKS_HOST="https://test.databricks.com" \
          DATABRICKS_TOKEN="test-token" \
          python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 &
          # Wait for backend to be ready
          for i in {1..30}; do
            if curl -s http://localhost:8000/api/health > /dev/null 2>&1; then
              echo "Backend is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "Backend failed to start"
              exit 1
            fi
            echo "Waiting for backend... ($i/30)"
            sleep 1
          done

      - name: Run E2E tests
        working-directory: frontend
        env:
          CI: true
          VITE_API_URL: http://localhost:8000
        run: npx playwright test --project=chromium

      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: frontend/playwright-report/

      - name: Upload Playwright test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-results
          path: frontend/test-results/

  # Validation tests - focused on deck integrity
  validation-tests:
    name: Deck Integrity Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run deck integrity tests
        run: |
          pytest tests/unit/test_deck_integrity.py tests/unit/test_llm_edit_responses.py -v -n auto \
            --tb=long \
            --junitxml=test-results/integrity-results.xml

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: validation-test-results
          path: test-results/

  # Persistence tests - verify all operations save to database
  persistence-tests:
    name: Deck Persistence Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run persistence tests
        run: |
          pytest tests/unit/test_deck_persistence.py tests/unit/test_chat_persistence.py -v -n auto \
            --tb=long \
            --junitxml=test-results/persistence-results.xml

      - name: Upload persistence test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: persistence-test-results
          path: test-results/

  # Summary job - runs after all tests
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, validation-tests, persistence-tests]
    if: always()
    steps:
      - name: Check test results
        run: |
          if [ "${{ needs.unit-tests.result }}" == "failure" ] || \
             [ "${{ needs.integration-tests.result }}" == "failure" ] || \
             [ "${{ needs.e2e-tests.result }}" == "failure" ] || \
             [ "${{ needs.validation-tests.result }}" == "failure" ] || \
             [ "${{ needs.persistence-tests.result }}" == "failure" ]; then
            echo "One or more test jobs failed"
            exit 1
          fi
          echo "All tests passed!"
